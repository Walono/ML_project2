{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 images\n",
      "(80, 400, 400, 3) (80, 400, 400)\n",
      "(80, 400, 400, 3) (80, 400, 400)\n",
      "x_train shape: (80, 400, 400, 3)\n",
      "80 train samples\n",
      "20 test samples\n",
      "(80, 400, 400, 2)\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# Load the training set\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([mpimg.imread(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = np.asarray([mpimg.imread(gt_dir + files[i]) for i in range(n)])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, gt_imgs, test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# input image dimensions\n",
    "img_dim = 400\n",
    "div = 1\n",
    "if img_dim % div != 0:\n",
    "    print(\"Invalid divider for the image dimensions!\")\n",
    "img_rows, img_cols = img_dim//div, img_dim//div\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0]*div*div, img_rows, img_cols, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0]*div*div, img_rows, img_cols, 3)\n",
    "    \n",
    "y_train = y_train.reshape(y_train.shape[0]*div*div, img_rows, img_cols)\n",
    "y_test = y_test.reshape(y_test.shape[0]*div*div, img_rows, img_cols)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "window_size = 30\n",
    "patch_size = 16\n",
    "input_shape = (window_size, window_size, 3)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "print(y_train.shape)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def generate_minibatch(X, Y):\n",
    "    \"\"\"\n",
    "    Procedure for real-time minibatch creation and image augmentation.\n",
    "    This runs in a parallel thread while the model is being trained.\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        # Generate one minibatch\n",
    "        X_batch = np.empty((batch_size, window_size, window_size, 3))\n",
    "        Y_batch = np.empty((batch_size, 2))\n",
    "        for i in range(batch_size):\n",
    "            # Select a random image\n",
    "            idx = np.random.choice(X.shape[0])\n",
    "            shape = X[idx].shape\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            center = np.random.randint(window_size//2, shape[0] - window_size//2, 2)\n",
    "            sub_image = X[idx][center[0]-window_size//2:center[0]+window_size//2,\n",
    "                               center[1]-window_size//2:center[1]+window_size//2]\n",
    "            gt_sub_image = Y[idx][center[0]-patch_size//2:center[0]+patch_size//2,\n",
    "                                  center[1]-patch_size//2:center[1]+patch_size//2]\n",
    "\n",
    "            # The label does not depend on the image rotation/flip (provided that the rotation is in steps of 90Â°)\n",
    "            threshold = 0.25\n",
    "            label = (np.array([np.mean(gt_sub_image)]) > threshold) * 1\n",
    "\n",
    "            label = np_utils.to_categorical(label, num_classes)\n",
    "            X_batch[i] = sub_image\n",
    "            Y_batch[i] = label\n",
    "\n",
    "        yield (X_batch, Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "5/5 [==============================] - 2s 436ms/step - loss: 0.6791 - acc: 0.8438\n",
      "Epoch 2/12\n",
      "5/5 [==============================] - 2s 395ms/step - loss: 0.4074 - acc: 1.0000\n",
      "Epoch 3/12\n",
      "5/5 [==============================] - 2s 341ms/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 4/12\n",
      "5/5 [==============================] - 2s 364ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 5/12\n",
      "5/5 [==============================] - 2s 390ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/12\n",
      "5/5 [==============================] - 2s 372ms/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 7/12\n",
      "5/5 [==============================] - 2s 365ms/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 8/12\n",
      "5/5 [==============================] - 2s 339ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 9/12\n",
      "5/5 [==============================] - 2s 347ms/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 10/12\n",
      "5/5 [==============================] - 2s 379ms/step - loss: 9.1527e-04 - acc: 1.0000\n",
      "Epoch 11/12\n",
      "5/5 [==============================] - 2s 362ms/step - loss: 8.0776e-04 - acc: 1.0000\n",
      "Epoch 12/12\n",
      "5/5 [==============================] - 2s 347ms/step - loss: 5.9198e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb62eb2cc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generate_minibatch(x_train, y_train),\n",
    "                    steps_per_epoch=5,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.000224461462494\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "xy_test_window = list(itertools.islice(generate_minibatch(x_test, y_test), 10))\n",
    "# TODO real testing and prediction of the patches\n",
    "xxx = list(zip(*xy_test_window))\n",
    "score = model.evaluate(xxx[0][0], xxx[1][0], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
