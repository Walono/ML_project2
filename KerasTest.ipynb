{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100 images\n",
      "Loading 100 images\n",
      "(80, 400, 400, 3) (80, 400, 400)\n",
      "(80, 400, 400, 3) (80, 400, 400)\n",
      "x_train shape: (80, 400, 400, 3)\n",
      "80 train samples\n",
      "20 test samples\n",
      "(80, 400, 400, 2)\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "# Load the training set\n",
    "root_dir = \"training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = len(files)\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = np.asarray([mpimg.imread(image_dir + files[i]) for i in range(n)])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = np.asarray([mpimg.imread(gt_dir + files[i]) for i in range(n)])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, gt_imgs, test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "# input image dimensions\n",
    "img_dim = 400\n",
    "div = 1\n",
    "if img_dim % div != 0:\n",
    "    print(\"Invalid divider for the image dimensions!\")\n",
    "img_rows, img_cols = img_dim//div, img_dim//div\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0]*div*div, img_rows, img_cols, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0]*div*div, img_rows, img_cols, 3)\n",
    "    \n",
    "y_train = y_train.reshape(y_train.shape[0]*div*div, img_rows, img_cols)\n",
    "y_test = y_test.reshape(y_test.shape[0]*div*div, img_rows, img_cols)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "    \n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 50\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "window_size = 72\n",
    "patch_size = 16\n",
    "input_shape = (window_size, window_size, 3)\n",
    "padding = (window_size - patch_size) // 2\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "print(y_train.shape)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def generate_minibatch(X, Y):\n",
    "    \"\"\"\n",
    "    Procedure for real-time minibatch creation and image augmentation.\n",
    "    This runs in a parallel thread while the model is being trained.\n",
    "    \"\"\"\n",
    "    while 1:\n",
    "        # Generate one minibatch\n",
    "        X_batch = np.empty((batch_size, window_size, window_size, 3))\n",
    "        Y_batch = np.empty((batch_size, 2))\n",
    "        for i in range(batch_size):\n",
    "            # Select a random image\n",
    "            idx = np.random.choice(X.shape[0])\n",
    "            shape = X[idx].shape\n",
    "\n",
    "            # Sample a random window from the image\n",
    "            center = np.random.randint(window_size//2, shape[0] - window_size//2, 2)\n",
    "            sub_image = X[idx][center[0]-window_size//2:center[0]+window_size//2,\n",
    "                               center[1]-window_size//2:center[1]+window_size//2]\n",
    "            gt_sub_image = Y[idx][center[0]-patch_size//2:center[0]+patch_size//2,\n",
    "                                  center[1]-patch_size//2:center[1]+patch_size//2]\n",
    "\n",
    "            # The label does not depend on the image rotation/flip (provided that the rotation is in steps of 90Â°)\n",
    "            threshold = 0.25\n",
    "            label = (np.array([np.mean(gt_sub_image)]) > threshold) * 1\n",
    "\n",
    "            label = np_utils.to_categorical(label, num_classes)\n",
    "            X_batch[i] = sub_image\n",
    "            Y_batch[i] = label\n",
    "\n",
    "        yield (X_batch, Y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 51/100 [==============>...............] - ETA: 1:23 - loss: 0.0665 - acc: 0.9936"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generate_minibatch(x_train, y_train),\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.000315213954309\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "xy_test_window = list(itertools.islice(generate_minibatch(x_test, y_test), 10))\n",
    "# TODO real testing and prediction of the patches\n",
    "xxx = list(zip(*xy_test_window))\n",
    "score = model.evaluate(xxx[0][0], xxx[1][0], verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('wight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(model, X):\n",
    "    \"\"\"\n",
    "    Classify an unseen set of samples.\n",
    "    This method must be called after \"train\".\n",
    "    Returns a list of predictions.\n",
    "    \"\"\"\n",
    "    # Subdivide the images into blocks\n",
    "    #/!\\ change the patch_size and padding elements to something real!\n",
    "    img_patches = create_patches(X, patch_size, 16, padding)\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        img_patches = np.rollaxis(img_patches, 3, 1)\n",
    "\n",
    "    # Run prediction\n",
    "    Z = model.model.predict(img_patches)\n",
    "    Z = (Z[:,0] < Z[:,1]) * 1\n",
    "\n",
    "    # Regroup patches into images\n",
    "    return group_patches(Z, X.shape[0])\n",
    "\n",
    "def load_image(infilename):\n",
    "    \"\"\" Load an image from disk. \"\"\"\n",
    "    return mpimg.imread(infilename)\n",
    "\n",
    "def pad_image(data, padding):\n",
    "    \"\"\"\n",
    "    Extend the canvas of an image. Mirror boundary conditions are applied.\n",
    "    \"\"\"\n",
    "    if len(data.shape) < 3:\n",
    "        # Greyscale image (ground truth)\n",
    "        data = np.lib.pad(data, ((padding, padding), (padding, padding)), 'reflect')\n",
    "    else:\n",
    "        # RGB image\n",
    "        data = np.lib.pad(data, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
    "    return data\n",
    "    \n",
    "def img_crop_gt(im, w, h, stride):\n",
    "    \"\"\" Crop an image into patches (this method is intended for ground truth images). \"\"\"\n",
    "    assert len(im.shape) == 2, 'Expected greyscale image.'\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    for i in range(0,imgheight,stride):\n",
    "        for j in range(0,imgwidth,stride):\n",
    "            im_patch = im[j:j+w, i:i+h]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "    \n",
    "def img_crop(im, w, h, stride, padding):\n",
    "    \"\"\" Crop an image into patches, taking into account mirror boundary conditions. \"\"\"\n",
    "    assert len(im.shape) == 3, 'Expected RGB image.'\n",
    "    list_patches = []\n",
    "    imgwidth = im.shape[0]\n",
    "    imgheight = im.shape[1]\n",
    "    im = np.lib.pad(im, ((padding, padding), (padding, padding), (0,0)), 'reflect')\n",
    "    for i in range(padding,imgheight+padding,stride):\n",
    "        for j in range(padding,imgwidth+padding,stride):\n",
    "            im_patch = im[j-padding:j+w+padding, i-padding:i+h+padding, :]\n",
    "            list_patches.append(im_patch)\n",
    "    return list_patches\n",
    "    \n",
    "def create_patches(X, patch_size, stride, padding):\n",
    "    img_patches = np.asarray([img_crop(X[i], patch_size, patch_size, stride, padding) for i in range(X.shape[0])])\n",
    "    # Linearize list\n",
    "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3], img_patches.shape[4])\n",
    "    return img_patches\n",
    "    \n",
    "def create_patches_gt(X, patch_size, stride):\n",
    "    img_patches = np.asarray([img_crop_gt(X[i], patch_size, patch_size, stride) for i in range(X.shape[0])])\n",
    "    # Linearize list\n",
    "    img_patches = img_patches.reshape(-1, img_patches.shape[2], img_patches.shape[3])\n",
    "    return img_patches\n",
    "    \n",
    "def group_patches(patches, num_images):\n",
    "    return patches.reshape(num_images, -1)\n",
    "\n",
    "def extract_img_features(filename, stride):\n",
    "    img = load_image(filename)\n",
    "    img_patches = img_crop(img, patch_size, patch_size, stride, padding)\n",
    "    X = np.asarray([img_patches[i] for i in range(len(img_patches))])\n",
    "    return X\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(model, image_filename):\n",
    "    \"\"\" Reads a single image and outputs the strings that should go into the submission file. \"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    Xi = load_image(image_filename)\n",
    "    Xi = Xi.reshape(1, Xi.shape[0], Xi.shape[1], Xi.shape[2])\n",
    "    Zi = classify(model, Xi)\n",
    "    Zi = Zi.reshape(-1)\n",
    "    patch_size = 16\n",
    "    nb = 0\n",
    "    print(\"Processing \" + image_filename)\n",
    "    for j in range(0, Xi.shape[2], patch_size):\n",
    "        for i in range(0, Xi.shape[1], patch_size):\n",
    "            label = int(Zi[nb])\n",
    "            nb += 1\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def generate_submission(model, submission_filename, *image_filenames):\n",
    "    \"\"\" Generate a .csv containing the classification of the test set. \"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(model, fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the weigt file and generate submission file\n",
    "This have to go on the run.py then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5_input (InputLayer)  (None, 72, 72, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 68, 68, 64)        4864      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 66, 66, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 69696)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8921216   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 8,963,266\n",
      "Trainable params: 8,963,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Processing test_set_images/test_1/test_1.png\n",
      "Processing test_set_images/test_2/test_2.png\n",
      "Processing test_set_images/test_3/test_3.png\n",
      "Processing test_set_images/test_4/test_4.png\n",
      "Processing test_set_images/test_5/test_5.png\n",
      "Processing test_set_images/test_6/test_6.png\n",
      "Processing test_set_images/test_7/test_7.png\n",
      "Processing test_set_images/test_8/test_8.png\n",
      "Processing test_set_images/test_9/test_9.png\n",
      "Processing test_set_images/test_10/test_10.png\n",
      "Processing test_set_images/test_11/test_11.png\n",
      "Processing test_set_images/test_12/test_12.png\n",
      "Processing test_set_images/test_13/test_13.png\n",
      "Processing test_set_images/test_14/test_14.png\n",
      "Processing test_set_images/test_15/test_15.png\n",
      "Processing test_set_images/test_16/test_16.png\n",
      "Processing test_set_images/test_17/test_17.png\n",
      "Processing test_set_images/test_18/test_18.png\n",
      "Processing test_set_images/test_19/test_19.png\n",
      "Processing test_set_images/test_20/test_20.png\n",
      "Processing test_set_images/test_21/test_21.png\n",
      "Processing test_set_images/test_22/test_22.png\n",
      "Processing test_set_images/test_23/test_23.png\n",
      "Processing test_set_images/test_24/test_24.png\n",
      "Processing test_set_images/test_25/test_25.png\n",
      "Processing test_set_images/test_26/test_26.png\n",
      "Processing test_set_images/test_27/test_27.png\n",
      "Processing test_set_images/test_28/test_28.png\n",
      "Processing test_set_images/test_29/test_29.png\n",
      "Processing test_set_images/test_30/test_30.png\n",
      "Processing test_set_images/test_31/test_31.png\n",
      "Processing test_set_images/test_32/test_32.png\n",
      "Processing test_set_images/test_33/test_33.png\n",
      "Processing test_set_images/test_34/test_34.png\n",
      "Processing test_set_images/test_35/test_35.png\n",
      "Processing test_set_images/test_36/test_36.png\n",
      "Processing test_set_images/test_37/test_37.png\n",
      "Processing test_set_images/test_38/test_38.png\n",
      "Processing test_set_images/test_39/test_39.png\n",
      "Processing test_set_images/test_40/test_40.png\n",
      "Processing test_set_images/test_41/test_41.png\n",
      "Processing test_set_images/test_42/test_42.png\n",
      "Processing test_set_images/test_43/test_43.png\n",
      "Processing test_set_images/test_44/test_44.png\n",
      "Processing test_set_images/test_45/test_45.png\n",
      "Processing test_set_images/test_46/test_46.png\n",
      "Processing test_set_images/test_47/test_47.png\n",
      "Processing test_set_images/test_48/test_48.png\n",
      "Processing test_set_images/test_49/test_49.png\n",
      "Processing test_set_images/test_50/test_50.png\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('wight.h5')\n",
    "\n",
    "model.model.summary()\n",
    "\n",
    "submission_filename = 'submission.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'test_set_images/test_'+str(i)+'/test_' + str(i) + '.png'\n",
    "    image_filenames.append(image_filename)\n",
    "    \n",
    "\n",
    "generate_submission(model, submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
